{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f9549-6192-4916-93fe-1976b90afdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from eval import *\n",
    "from data import FacesDataset, data_transform\n",
    "import time\n",
    "# from ..utils.data import FacesDataset, data_transform\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from demo import RequestDetails, process_request, process_request_with_accuracy, process_batch_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147ae96-dd4d-4add-bad3-4fdea7e7c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_request(request_details):\n",
    "\tmodel_to_use = None\n",
    "\t# print(three_task_table)\n",
    "\ttask_count = len(request_details.tasks)\n",
    "\tif(task_count > 1):\n",
    "\t\tfor latency in three_task_table[\"age\"]:\n",
    "\t\t\tif(latency <= request_details.latency):\n",
    "\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\tmodel_to_use = three_task_table[\"age\"][latency]\n",
    "\t\t\t\telse:\t\n",
    "\t\t\t\t\tmean_acc = (float(three_task_table[\"age\"][latency].accuracy[0]) + float(three_task_table[\"gender\"][latency].accuracy[1]) + float(three_task_table[\"ethnicity\"][latency].accuracy[2])) / 3.0\n",
    "\t\t\t\t\tmean_acc_existing = (float(model_to_use.accuracy[0]) + float(model_to_use.accuracy[1]) + float(model_to_use.accuracy[2]))/3.0 \n",
    "\t\t\t\t\tif(mean_acc_existing < mean_acc): model_to_use = three_task_table[\"age\"][latency] \n",
    "\telse:\n",
    "\t\tif(request_details.tasks[0] == \"age\"):\n",
    "\t\t\tfor latency in age_task_table[\"age\"]:\n",
    "\t\t\t\tif(latency <= request_details.latency):\n",
    "\t\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\t\tmodel_to_use = age_task_table[\"age\"][latency]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif(model_to_use.accuracy[0] < float(age_task_table[\"age\"][latency].accuracy[0])):\n",
    "\t\t\t\t\t\t\tmodel_to_use = age_task_table[\"age\"][latency]\n",
    "\t\telif(request_details.tasks[0] == \"gender\"):\n",
    "\t\t\tfor latency in gender_task_table[\"gender\"]:\n",
    "\t\t\t\tif(latency <= request_details.latency):\n",
    "\t\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\t\tmodel_to_use = gender_task_table[\"gender\"][latency]\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif(model_to_use.accuracy[0] < float(gender_task_table[\"gender\"][latency].accuracy[0])):\n",
    "\t\t\t\t\t\t\tmodel_to_use = gender_task_table[\"gender\"][latency]\n",
    "\t\telif(request_details.tasks[0] == \"ethnicity\"):\t\n",
    "\t\t\tfor latency in ethnicity_task_table[\"ethnicity\"]:\n",
    "\t\t\t\tif(latency <= request_details.latency):\n",
    "\t\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\t\tmodel_to_use = ethnicity_task_table[\"ethnicity\"][latency]\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif(model_to_use.accuracy[0] < float(ethnicity_task_table[\"ethnicity\"][latency].accuracy[0])):\n",
    "\t\t\t\t\t\t\tmodel_to_use = ethnicity_task_table[\"ethnicity\"][latency]\n",
    "\n",
    "\tif(model_to_use == None):\n",
    "\t\t## Cannot meet latency requirement with any model\n",
    "\t\treturn None, None\n",
    "\telse:\n",
    "\t\tmodel = torch.load(model_to_use.file_path, map_location=torch.device('cpu'))\n",
    "\t\t# model = torch.load(model_to_use.file_path)\n",
    "\t\t# model.cuda()\n",
    "\t\tmodel.cpu()\n",
    "\t\t# output = model(request_details.input_image.cuda())\n",
    "\t\treturn output, model_to_use.latency\n",
    "\t\tif(task_count > 1):\n",
    "\t\t\treturn output, (float(model_to_use.accuracy[0]) + float(model_to_use.accuracy[1]) + float(model_to_use.accuracy[2]))/3.0\n",
    "\t\telse:\n",
    "\t\t\treturn output, model_to_use.accuracy[0]\n",
    "\n",
    "def process_request_with_accuracy(request_details):\n",
    "\tmodel_to_use = None\n",
    "\ttask_count = len(request_details.tasks)\n",
    "\tif(task_count > 1):\n",
    "\t\tfor latency in three_task_table[\"age\"]:\n",
    "\t\t\t# print(float(three_task_table[\"gender\"][latency].accuracy[1]), request_details.accuracy[1])\n",
    "\t\t\tmean_acc = float(three_task_table[\"age\"][latency].accuracy[0]) >= request_details.accuracy[0] and\\\n",
    "\t\t\t\tfloat(three_task_table[\"gender\"][latency].accuracy[1]) >= request_details.accuracy[1] and\\\n",
    "\t\t\t\tfloat(three_task_table[\"ethnicity\"][latency].accuracy[2]) >= request_details.accuracy[2]\n",
    "\t\t\tif(latency <= request_details.latency-10 and mean_acc == True):\n",
    "\t\t\t\t\tmodel_to_use = three_task_table[\"age\"][latency]\n",
    "\telse:\n",
    "\t\tif(request_details.tasks[0] == \"age\"):\n",
    "\t\t\tfor latency in age_task_table[\"age\"]:\n",
    "\t\t\t\tif(latency <= request_details.latency-10 and float(age_task_table[\"age\"][latency].accuracy[0]) >= request_details.accuracy):\n",
    "\t\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\t\tmodel_to_use = age_task_table[\"age\"][latency]\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif(float(model_to_use.accuracy[0]) < float(age_task_table[\"age\"][latency].accuracy[0])):\n",
    "\t\t\t\t\t\t\tmodel_to_use = age_task_table[\"age\"][latency]\n",
    "\t\telif(request_details.tasks[0] == \"gender\"):\n",
    "\t\t\tfor latency in gender_task_table[\"gender\"]:\n",
    "\t\t\t\tif(latency <= request_details.latency-10and float(gender_task_table[\"gender\"][latency].accuracy[0]) >= request_details.accuracy):\n",
    "\t\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\t\tmodel_to_use = gender_task_table[\"gender\"][latency]\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif(float(model_to_use.accuracy[0]) < float(gender_task_table[\"gender\"][latency].accuracy[0])):\n",
    "\t\t\t\t\t\t\tmodel_to_use = gender_task_table[\"gender\"][latency]\n",
    "\t\telif(request_details.tasks[0] == \"ethnicity\"):\t\n",
    "\t\t\tfor latency in ethnicity_task_table[\"ethnicity\"]:\n",
    "\t\t\t\tif(latency <= request_details.latency-10 and float(ethnicity_task_table[\"ethnicity\"][latency].accuracy[0]) >= request_details.accuracy):\n",
    "\t\t\t\t\tif(model_to_use == None):\n",
    "\t\t\t\t\t\tmodel_to_use = ethnicity_task_table[\"ethnicity\"][latency]\t\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif(float(model_to_use.accuracy[0]) < float(ethnicity_task_table[\"ethnicity\"][latency].accuracy[0])):\n",
    "\t\t\t\t\t\t\tmodel_to_use = ethnicity_task_table[\"ethnicity\"][latency]\n",
    "\n",
    "\tif(model_to_use == None):\n",
    "\t\t## Cannot meet latency/accuracy requirement with any model\n",
    "\t\treturn None, None\n",
    "\telse:\n",
    "\t\t# print(\"asd\", request_details.tasks)\n",
    "\t\t# print(model_to_use.latency, end=\" \")\n",
    "\t\tmodel = torch.load(model_to_use.file_path, map_location=torch.device('cpu'))\n",
    "\t\t# model = torch.load(model_to_use.file_path)\n",
    "\t\t# model.cuda()\n",
    "\t\tmodel.cpu()\n",
    "\t\t# output = model(request_details.input_image.cuda())\n",
    "\t\toutput = model(request_details.input_image)\n",
    "\t\treturn output, model_to_use.accuracy[0]\n",
    "\t\t# return output, model_to_use.latency\n",
    "\n",
    "def process_batch_requests(requests, min_accuracy=False, mtl_model=True, only_mtl=False):\n",
    "\tuse_gpu = False\n",
    "\t## Can write some queing stuff\n",
    "\t## iterate on the requests and call process_request\n",
    "\tlatency_hit = []\n",
    "\taccuracy_hit = []\n",
    "\tlat_acc_pair = []\n",
    "\toutputs, latencies = [], []\n",
    "\tfor request in requests:\n",
    "\t\tif(min_accuracy):\n",
    "\t\t\tif use_gpu: # skip first sample (to avoid slow GPU processing on first sample)\n",
    "\t\t\t\tif(only_mtl):\n",
    "\t\t\t\t\toutput, accuracy = process_request_only_mtl(request, with_accuracy=True)\n",
    "\t\t\t\telif(mtl_model):\n",
    "\t\t\t\t\toutput, accuracy = process_request_with_accuracy(request)\n",
    "\t\t\t\telse:                \n",
    "\t\t\t\t\toutput, accuracy = process_request_single_model_system(request, with_accuracy=True)\n",
    "                    \n",
    "\t\t\tstart_time = time.time()\n",
    "\t\t\tif(only_mtl):\n",
    "\t\t\t\toutput, accuracy = process_request_only_mtl(request, with_accuracy=True)\n",
    "\t\t\telif(mtl_model):\n",
    "\t\t\t\toutput, accuracy = process_request_with_accuracy(request)\n",
    "\t\t\telse:                \n",
    "\t\t\t\toutput, accuracy = process_request_single_model_system(request, with_accuracy=True)\n",
    "\t\t\tend_time = time.time()\n",
    "\t\t\tinf_time = (end_time-start_time)*1000\n",
    "\t\t\t# print(inf_time, request.latency, accuracy)\n",
    "\t\t\t# print(inf_time, start_time, end_time)\n",
    "\t\t\t# print(inf_time)\n",
    "\t\t\toutputs.append(output)\n",
    "\t\t\tlatencies.append(inf_time)\n",
    "\t\t\tif(inf_time <= request.latency + 5 and output!=None):\n",
    "\t\t\t\tlatency_hit.append(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlatency_hit.append(0)\n",
    "\n",
    "\t\t\tif(accuracy!=None ):\n",
    "\t\t\t\taccuracy_hit.append(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\taccuracy_hit.append(0)\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tif use_gpu: # skip first sample (to avoid slow GPU processing on first sample)\n",
    "\t\t\t\tif(only_mtl):\n",
    "\t\t\t\t\toutput, accuracy = process_request_only_mtl(request)\n",
    "\t\t\t\telif(mtl_model):\n",
    "\t\t\t\t\toutput, accuracy = process_request(request)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\toutput, accuracy = process_request_single_model_system(request)                \n",
    "\t\t\tstart_time = time.time()\n",
    "\t\t\tif(only_mtl):\n",
    "\t\t\t\toutput, accuracy = process_request_only_mtl(request)\n",
    "\t\t\telif(mtl_model):\n",
    "\t\t\t\toutput, accuracy = process_request(request)\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput, accuracy = process_request_single_model_system(request)\n",
    "\t\t\tend_time = time.time()\n",
    "\t\t\tinf_time = (end_time-start_time)*1000\n",
    "\t\t\t# print(inf_time, request.latency, accuracy)\n",
    "\t\t\t# print(inf_time, end_time, output)\n",
    "\t\t\tif(inf_time <= request.latency and output!=None):\n",
    "\t\t\t\tlatency_hit.append(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlatency_hit.append(0)\n",
    "\t\t\tif (accuracy != None):\n",
    "\t\t\t\tlat_acc_pair.append([request.latency, accuracy])\n",
    "\treturn outputs, latencies\n",
    "\t# return latency_hit, accuracy_hit, lat_acc_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43957e7d-5958-4292-8def-926df873308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in the data\n",
    "folder = '../UTKFace'\n",
    "transform = data_transform()\n",
    "dataset = FacesDataset(folder=folder, transform=transform)\n",
    "\n",
    "train_len = int(len(dataset)*0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_len, val_len], torch.Generator().manual_seed(8))\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaaee6a-2cc6-4c23-b42e-bcbd48f3d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading all task models..\")\n",
    "### All three tasks\n",
    "three_task_models = load_all_task_models_info(dataloader, \"model_score_lookup_multitask.tsv\", \"../models/model_variants\")\n",
    "three_task_table = get_models_table(three_task_models)\n",
    "\n",
    "print(\"Loading age models..\")\n",
    "### Age\n",
    "age_task_models = load_one_task_models_info(dataloader, \"model_score_lookup_multitask.tsv\", \"../models/model_variants\", \"age\", True)\n",
    "age_task_table = get_models_table(age_task_models)\n",
    "print(\"Loading gender models..\")\n",
    "### Gender\n",
    "gender_task_models = load_one_task_models_info(dataloader, \"model_score_lookup_multitask.tsv\", \"../models/model_variants\", \"gender\", True)\n",
    "gender_task_table = get_models_table(gender_task_models)\n",
    "\n",
    "print(\"Loading ethnicity models..\")\n",
    "### Ethnicity\n",
    "ethnicity_task_models = load_one_task_models_info(dataloader, \"model_score_lookup_multitask.tsv\", \"../models/model_variants/\", \"ethnicity\", True)\n",
    "ethnicity_task_table = get_models_table(ethnicity_task_models)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb202e6-15d9-4ee2-9bc4-e79a17e4fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency = int(max(three_task_table[\"age\"]))+10\n",
    "\n",
    "data = next(iter(dataloader))\n",
    "input_image = data[0][0]\n",
    "age = data[1][0]\n",
    "gender = data[2][0]\n",
    "ethnicity = data[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52793f-d978-4b59-a930-3c36e0da245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = []\n",
    "accuracy = [0.83, 0.92, 0.72] \n",
    "accuracy1 = [0.75, 0.90, 0.70]\n",
    "requests.append(RequestDetails(accuracy, latency, [\"age\", \"gender\", \"ethnicity\"], input_image.unsqueeze(0)))\n",
    "requests.append(RequestDetails(accuracy[0], latency, [\"age\"], input_image.unsqueeze(0)))\n",
    "requests.append(RequestDetails(accuracy[1], latency, [\"gender\"], input_image.unsqueeze(0)))                                \n",
    "requests.append(RequestDetails(accuracy[2], latency, [\"ethnicity\"], input_image.unsqueeze(0)))\n",
    "requests.append(RequestDetails(accuracy1[0], latency-20, [\"age\"], input_image.unsqueeze(0)))\n",
    "\n",
    "outputs, latencies = process_batch_requests(requests, min_accuracy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557521d-2539-490d-9126-64cea7d7832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(outputs)):\n",
    "    output = outputs[i]\n",
    "    age_output, gender_output, ethnicity_output = output\n",
    "    age_output = age_output.squeeze(1)\n",
    "    gender_output = gender_output\n",
    "    ethnicity_output = ethnicity_output\n",
    "    age_pred = age_output\n",
    "    gender_pred = torch.argmax(gender_output, axis=1)\n",
    "    ethnicity_pred = torch.argmax(ethnicity_output, axis=1)\n",
    "    outputs[i] = [age_pred, gender_pred, ethnicity_pred]\n",
    "outputs[0] = [outputs[0][0].cpu().item(), outputs[0][1].cpu().item(), outputs[0][2].cpu().item()]\n",
    "outputs[1] = [outputs[1][0].cpu().item()]\n",
    "outputs[2] = [outputs[2][1].cpu().item()]\n",
    "outputs[3] = [outputs[3][2].cpu().item()]\n",
    "outputs[4] = [outputs[4][0].cpu().item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc9c73-379f-438d-ab0a-63a449a85d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "age, gender, ethnicity, latency #Ground Truth\n",
    "outputs, latencies # Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db655db2-9794-4f4c-8b5c-361cbc321b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3772a-d535-4900-b147-aba5b326563a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89b89d-c8f3-4647-8d8f-1fa42e9cd286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
