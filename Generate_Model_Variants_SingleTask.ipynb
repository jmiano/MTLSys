{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import sklearn.metrics as perf\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch_pruning as tp\n",
    "import csv\n",
    "\n",
    "from models.models import MTLClassifier, AgeRegressor, GenderClassifier, EthnicityClassifier\n",
    "from utils.data import FacesDataset, data_transform\n",
    "from utils.training import train_mtl_model, train_age_model, train_gender_model, train_ethnicity_model\n",
    "from utils.evaluation import run_evaluation, show_example_predictions\n",
    "from utils.pruning import prune_model, prune_other_tasks, get_f1_and_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in the data\n",
    "folder = 'UTKFace'\n",
    "transform = data_transform()\n",
    "dataset = FacesDataset(folder=folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up train and val datasets and loaders\n",
    "train_len = int(len(dataset)*0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_dataset, val_dataset = random_split(dataset, [train_len, val_len], torch.Generator().manual_seed(8))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get small subset fpr train_loader and val_loader (for testing and debugging)\n",
    "# train_indices = torch.randperm(len(train_dataset))[:100]\n",
    "# val_indices = torch.randperm(len(val_dataset))[:100]\n",
    "# train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "# val_subset = torch.utils.data.Subset(val_dataset, val_indices)\n",
    "# train_loader = DataLoader(dataset=train_subset, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(dataset=val_subset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTL Model Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define pruned training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruned_mtl_training(task, prune_pct, num_epochs,\n",
    "                        train_loader=train_loader, val_loader=val_loader,\n",
    "                        val_dataset=None):\n",
    "    \n",
    "    ### Set up model, loss, and optimizer\n",
    "    if task.upper()=='GENDER':\n",
    "        tasks = ['gender']\n",
    "        model = GenderClassifier()\n",
    "        model = model.cuda()\n",
    "        gender_criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Set up and run model training\n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init_SingleTaskModel.pth'\n",
    "        train_gender_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                           train_loader=train_loader, val_loader=val_loader,\n",
    "                           gender_criterion=gender_criterion, gender_coeff=1.0,\n",
    "                           save=True, save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_other_tasks(model, task1='age', task2='ethnicity', PRUNING_PERCENT=prune_pct)\n",
    "        pruned_optimizer = torch.optim.Adam(pruned_model.parameters())\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init_SingleTaskModel.pth'\n",
    "        train_gender_model(num_epochs=num_epochs, model=pruned_model, optimizer=pruned_optimizer,\n",
    "                           train_loader=train_loader, val_loader=val_loader,\n",
    "                           gender_criterion=gender_criterion, gender_coeff=1.0,\n",
    "                           save=True, save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                   eval_dataset=val_dataset,\n",
    "                                                   eval_dataloader=val_loader,\n",
    "                                                   tasks=tasks,\n",
    "                                                   mtl_model=False)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        genderf1 = scores['gender'][0]\n",
    "        row = [task.upper(), prune_pct, mean_lat, std_lat, 0.0, genderf1, 0.0]\n",
    "        with open('models/model_variants/model_score_lookup_singletask.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_SingleTaskModel.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "    elif task.upper()=='ETHNICITY':\n",
    "        tasks = ['ethnicity']\n",
    "        model = EthnicityClassifier()\n",
    "        model = model.cuda()\n",
    "        ethnicity_criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Set up and run model training\n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init_SingleTaskModel.pth'\n",
    "        train_ethnicity_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              ethnicity_criterion=ethnicity_criterion, ethnicity_coeff=1.0,\n",
    "                              save=True, save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_other_tasks(model, task1='age', task2='gender', PRUNING_PERCENT=prune_pct)\n",
    "        pruned_optimizer = torch.optim.Adam(pruned_model.parameters())\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init_SingleTaskModel.pth'\n",
    "        train_ethnicity_model(num_epochs=num_epochs, model=pruned_model, optimizer=pruned_optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              ethnicity_criterion=ethnicity_criterion, ethnicity_coeff=1.0,\n",
    "                              save=True, save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                       eval_dataset=val_dataset,\n",
    "                                                       eval_dataloader=val_loader,\n",
    "                                                       tasks=tasks,\n",
    "                                                       mtl_model=False)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        ethnicityf1 = scores['ethnicity'][0]\n",
    "        row = [task.upper(), prune_pct, mean_lat, std_lat, 0.0, 0.0, ethnicityf1]\n",
    "        with open('models/model_variants/model_score_lookup_singletask.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_SingleTaskModel.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "    elif task.upper()=='AGE':\n",
    "        tasks = ['age']\n",
    "        model = AgeRegressor()\n",
    "        model = model.cuda()\n",
    "        age_criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Set up and run model training\n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init_SingleTaskModel.pth'\n",
    "        train_age_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              age_criterion=age_criterion, age_coeff=1.0,\n",
    "                              save=True, save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_other_tasks(model, task1='gender', task2='ethnicity', PRUNING_PERCENT=prune_pct)\n",
    "        pruned_optimizer = torch.optim.Adam(pruned_model.parameters())\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init_SingleTaskModel.pth'\n",
    "        train_age_model(num_epochs=num_epochs, model=pruned_model, optimizer=pruned_optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              age_criterion=age_criterion, age_coeff=1.0,\n",
    "                              save=True, save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                       eval_dataset=val_dataset,\n",
    "                                                       eval_dataloader=val_loader,\n",
    "                                                       tasks=tasks,\n",
    "                                                       mtl_model=False)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        ager2 = scores['age'][1]\n",
    "        row = [task.upper(), prune_pct, mean_lat, std_lat, ager2, 0.0, 0.0]\n",
    "        with open('models/model_variants/model_score_lookup_singletask.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_SingleTaskModel.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "    else:\n",
    "        print('Invalid task was specified.')\n",
    "        \n",
    "    # Delete intermediate model files\n",
    "    os.remove(f'models/{save_initial}')\n",
    "    if save_initial != save_no_prune:\n",
    "        os.remove(f'models/{save_no_prune}')\n",
    "        \n",
    "    return scores, mean_lat, std_lat\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0% to 90% Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: pruning the linear task-specific layers was sometimes causing an index-out-of-bounds error, which I think is due to it pruning off the final layer. As a fix, trying ignoring the last layer when pruning the linear layers. Note: once I edited the linear layer pruning to not prune the last layer, this problem was resolved.\n",
    "\n",
    "However, pruning the linear layer caused more drastic performance decreases, so changed it to only prune the convolutional layers.\n",
    "\n",
    "Note: pruning causes poor performance. Things to try: reset optimizer before pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------- Prune 0 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 5.56717, train loss: 10.11769\n",
      "Epoch 1, val loss: 5.56717 -> 5.34095, train loss: 6.54983\n",
      "Epoch 2, val loss: 5.87016, train loss: 5.28468\n",
      "Epoch 3, val loss: 5.34095 -> 4.65103, train loss: 4.44471\n",
      "Epoch 4, val loss: 4.65103 -> 4.61679, train loss: 4.04575\n",
      "Epoch 5, val loss: 4.61679 -> 4.17793, train loss: 3.34958\n",
      "Epoch 6, val loss: 4.84131, train loss: 3.15393\n",
      "Epoch 7, val loss: 4.78454, train loss: 2.74433\n",
      "Epoch 8, val loss: 4.88639, train loss: 2.40511\n",
      "Epoch 9, val loss: 4.37812, train loss: 2.30983\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 8.02549, train loss: 3.23882\n",
      "Epoch 1, val loss: 8.02549 -> 3.94230, train loss: 2.75208\n",
      "Epoch 2, val loss: 4.08596, train loss: 2.39928\n",
      "Epoch 3, val loss: 4.68539, train loss: 2.17427\n",
      "Epoch 4, val loss: 3.94230 -> 3.75982, train loss: 1.89224\n",
      "Epoch 5, val loss: 3.90357, train loss: 1.74457\n",
      "Epoch 6, val loss: 3.88482, train loss: 1.65592\n",
      "Epoch 7, val loss: 3.98705, train loss: 1.54459\n",
      "Epoch 8, val loss: 3.96059, train loss: 1.41082\n",
      "Epoch 9, val loss: 3.98544, train loss: 1.40880\n",
      "\n",
      "--------------------------------- Prune 10 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 7.23549, train loss: 11.05839\n",
      "Epoch 1, val loss: 9.23793, train loss: 6.87332\n",
      "Epoch 2, val loss: 7.23549 -> 5.74513, train loss: 5.58398\n",
      "Epoch 3, val loss: 5.74513 -> 4.65576, train loss: 4.58212\n",
      "Epoch 4, val loss: 4.75496, train loss: 4.03980\n",
      "Epoch 5, val loss: 5.39197, train loss: 3.63344\n",
      "Epoch 6, val loss: 4.66017, train loss: 3.11845\n",
      "Epoch 7, val loss: 4.65576 -> 4.16203, train loss: 2.72474\n",
      "Epoch 8, val loss: 5.92399, train loss: 2.42957\n",
      "Epoch 9, val loss: 4.16203 -> 3.79169, train loss: 2.39010\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 5.21183, train loss: 2.20318\n",
      "Epoch 1, val loss: 5.21183 -> 4.20820, train loss: 1.91918\n",
      "Epoch 2, val loss: 4.20820 -> 3.79680, train loss: 1.76038\n",
      "Epoch 3, val loss: 4.15597, train loss: 1.60798\n",
      "Epoch 4, val loss: 3.87763, train loss: 1.44670\n",
      "Epoch 5, val loss: 3.90525, train loss: 1.46842\n",
      "Epoch 6, val loss: 3.79680 -> 3.64654, train loss: 1.33523\n",
      "Epoch 7, val loss: 4.17320, train loss: 1.26466\n",
      "Epoch 8, val loss: 3.76899, train loss: 1.25046\n",
      "Epoch 9, val loss: 3.68932, train loss: 1.14533\n",
      "\n",
      "--------------------------------- Prune 20 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 10.58894, train loss: 11.00696\n",
      "Epoch 1, val loss: 10.58894 -> 10.20420, train loss: 6.71406\n",
      "Epoch 2, val loss: 10.20420 -> 6.58011, train loss: 5.71378\n",
      "Epoch 3, val loss: 6.58011 -> 4.56414, train loss: 4.82926\n",
      "Epoch 4, val loss: 4.56414 -> 4.16544, train loss: 4.23784\n",
      "Epoch 5, val loss: 4.81014, train loss: 3.70221\n",
      "Epoch 6, val loss: 5.83379, train loss: 3.19425\n",
      "Epoch 7, val loss: 4.77815, train loss: 2.96622\n",
      "Epoch 8, val loss: 4.27478, train loss: 2.49786\n",
      "Epoch 9, val loss: 4.77450, train loss: 2.25683\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 6.95830, train loss: 4.20946\n",
      "Epoch 1, val loss: 6.95830 -> 4.71832, train loss: 3.30884\n",
      "Epoch 2, val loss: 4.71832 -> 4.40840, train loss: 2.94667\n",
      "Epoch 3, val loss: 4.95878, train loss: 2.58040\n",
      "Epoch 4, val loss: 4.40840 -> 4.26693, train loss: 2.42760\n",
      "Epoch 5, val loss: 4.26693 -> 3.88398, train loss: 2.29367\n",
      "Epoch 6, val loss: 4.12657, train loss: 1.88940\n",
      "Epoch 7, val loss: 5.94801, train loss: 1.95699\n",
      "Epoch 8, val loss: 3.91765, train loss: 1.84579\n",
      "Epoch 9, val loss: 4.19853, train loss: 1.55921\n",
      "\n",
      "--------------------------------- Prune 30 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 6.91029, train loss: 10.93618\n",
      "Epoch 1, val loss: 6.91029 -> 4.87571, train loss: 6.67685\n",
      "Epoch 2, val loss: 4.87571 -> 4.78096, train loss: 5.69653\n",
      "Epoch 3, val loss: 5.17841, train loss: 4.74053\n",
      "Epoch 4, val loss: 4.78096 -> 4.52128, train loss: 4.21322\n",
      "Epoch 5, val loss: 4.52128 -> 4.39367, train loss: 3.66801\n",
      "Epoch 6, val loss: 5.54238, train loss: 3.32481\n",
      "Epoch 7, val loss: 4.39367 -> 3.74699, train loss: 2.82614\n",
      "Epoch 8, val loss: 5.27216, train loss: 2.56977\n",
      "Epoch 9, val loss: 3.88283, train loss: 2.24557\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 5.01454, train loss: 3.49148\n",
      "Epoch 1, val loss: 5.65543, train loss: 2.59325\n",
      "Epoch 2, val loss: 5.01454 -> 4.48629, train loss: 2.52543\n",
      "Epoch 3, val loss: 4.48629 -> 3.97292, train loss: 2.13196\n",
      "Epoch 4, val loss: 3.97292 -> 3.88448, train loss: 1.99027\n",
      "Epoch 5, val loss: 3.99759, train loss: 1.79562\n",
      "Epoch 6, val loss: 3.95903, train loss: 1.61852\n",
      "Epoch 7, val loss: 4.38748, train loss: 1.56491\n",
      "Epoch 8, val loss: 4.15522, train loss: 1.46562\n",
      "Epoch 9, val loss: 4.35514, train loss: 1.38620\n",
      "\n",
      "--------------------------------- Prune 40 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 7.53277, train loss: 11.09024\n",
      "Epoch 1, val loss: 7.53277 -> 6.81308, train loss: 6.66274\n",
      "Epoch 2, val loss: 6.81308 -> 4.88073, train loss: 5.69417\n",
      "Epoch 3, val loss: 5.70285, train loss: 4.93473\n",
      "Epoch 4, val loss: 4.88073 -> 4.15125, train loss: 4.29798\n",
      "Epoch 5, val loss: 6.08818, train loss: 3.65613\n",
      "Epoch 6, val loss: 5.40184, train loss: 3.31253\n",
      "Epoch 7, val loss: 4.15125 -> 3.79712, train loss: 2.99367\n",
      "Epoch 8, val loss: 5.81129, train loss: 2.59605\n",
      "Epoch 9, val loss: 4.06407, train loss: 2.27259\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 4.40809, train loss: 4.98753\n",
      "Epoch 1, val loss: 6.36598, train loss: 3.13482\n",
      "Epoch 2, val loss: 4.42393, train loss: 2.90433\n",
      "Epoch 3, val loss: 4.40809 -> 4.18824, train loss: 2.43044\n",
      "Epoch 4, val loss: 4.86388, train loss: 2.29462\n",
      "Epoch 5, val loss: 4.39216, train loss: 2.14981\n",
      "Epoch 6, val loss: 4.26945, train loss: 1.90573\n",
      "Epoch 7, val loss: 4.19725, train loss: 1.82929\n",
      "Epoch 8, val loss: 5.00385, train loss: 1.66509\n",
      "Epoch 9, val loss: 4.30812, train loss: 1.56762\n",
      "\n",
      "--------------------------------- Prune 50 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 6.64270, train loss: 10.79482\n",
      "Epoch 1, val loss: 6.64270 -> 5.48322, train loss: 6.80377\n",
      "Epoch 2, val loss: 5.61439, train loss: 5.55016\n",
      "Epoch 3, val loss: 6.72320, train loss: 4.76122\n",
      "Epoch 4, val loss: 5.48322 -> 4.22638, train loss: 4.20044\n",
      "Epoch 5, val loss: 4.83490, train loss: 3.62360\n",
      "Epoch 6, val loss: 4.22638 -> 3.85129, train loss: 3.31315\n",
      "Epoch 7, val loss: 3.95419, train loss: 2.79637\n",
      "Epoch 8, val loss: 4.16864, train loss: 2.45786\n",
      "Epoch 9, val loss: 4.37454, train loss: 2.20179\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 5.42774, train loss: 9.04534\n",
      "Epoch 1, val loss: 6.58115, train loss: 4.86749\n",
      "Epoch 2, val loss: 5.42774 -> 4.69068, train loss: 4.11721\n",
      "Epoch 3, val loss: 4.85525, train loss: 3.54637\n",
      "Epoch 4, val loss: 5.06338, train loss: 3.36667\n",
      "Epoch 5, val loss: 5.29524, train loss: 2.93692\n",
      "Epoch 6, val loss: 4.69068 -> 4.50369, train loss: 2.68246\n",
      "Epoch 7, val loss: 4.53034, train loss: 2.42644\n",
      "Epoch 8, val loss: 4.50369 -> 4.46134, train loss: 2.32954\n",
      "Epoch 9, val loss: 4.71646, train loss: 2.08145\n",
      "\n",
      "--------------------------------- Prune 60 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 6.39834, train loss: 10.23879\n",
      "Epoch 1, val loss: 7.46281, train loss: 6.69063\n",
      "Epoch 2, val loss: 6.39834 -> 5.07097, train loss: 5.31666\n",
      "Epoch 3, val loss: 5.07097 -> 4.61407, train loss: 4.35932\n",
      "Epoch 4, val loss: 7.66194, train loss: 4.06060\n",
      "Epoch 5, val loss: 4.61407 -> 4.42075, train loss: 3.44462\n",
      "Epoch 6, val loss: 4.45207, train loss: 2.93563\n",
      "Epoch 7, val loss: 4.42075 -> 3.99123, train loss: 2.73127\n",
      "Epoch 8, val loss: 3.99342, train loss: 2.36734\n",
      "Epoch 9, val loss: 3.99123 -> 3.96505, train loss: 2.20046\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 8.40090, train loss: 13.94940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, val loss: 8.40090 -> 6.26513, train loss: 7.93040\n",
      "Epoch 2, val loss: 6.67422, train loss: 6.29963\n",
      "Epoch 3, val loss: 6.26513 -> 5.20368, train loss: 5.30288\n",
      "Epoch 4, val loss: 5.43756, train loss: 4.52305\n",
      "Epoch 5, val loss: 5.20368 -> 5.18966, train loss: 4.13952\n",
      "Epoch 6, val loss: 5.18966 -> 5.09850, train loss: 3.58393\n",
      "Epoch 7, val loss: 5.13607, train loss: 3.35669\n",
      "Epoch 8, val loss: 5.54167, train loss: 2.99933\n",
      "Epoch 9, val loss: 5.64975, train loss: 2.81623\n",
      "\n",
      "--------------------------------- Prune 70 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 5.75263, train loss: 10.52901\n",
      "Epoch 1, val loss: 6.34998, train loss: 6.42953\n",
      "Epoch 2, val loss: 5.75263 -> 4.79656, train loss: 5.36921\n",
      "Epoch 3, val loss: 4.79656 -> 4.43999, train loss: 4.71622\n",
      "Epoch 4, val loss: 5.09162, train loss: 4.08518\n",
      "Epoch 5, val loss: 6.18765, train loss: 3.50601\n",
      "Epoch 6, val loss: 4.43999 -> 4.08426, train loss: 3.31681\n",
      "Epoch 7, val loss: 4.23655, train loss: 2.80919\n",
      "Epoch 8, val loss: 4.86148, train loss: 2.55810\n",
      "Epoch 9, val loss: 4.08426 -> 3.95087, train loss: 2.20633\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 10.35432, train loss: 16.32272\n",
      "Epoch 1, val loss: 10.35432 -> 8.33519, train loss: 10.67311\n",
      "Epoch 2, val loss: 8.33519 -> 7.32456, train loss: 8.68061\n",
      "Epoch 3, val loss: 7.32456 -> 6.21375, train loss: 7.44759\n",
      "Epoch 4, val loss: 6.21375 -> 5.87958, train loss: 7.04551\n",
      "Epoch 5, val loss: 5.87958 -> 5.85951, train loss: 6.05039\n",
      "Epoch 6, val loss: 6.04731, train loss: 5.83226\n",
      "Epoch 7, val loss: 6.26373, train loss: 5.21154\n",
      "Epoch 8, val loss: 5.85951 -> 5.63220, train loss: 4.79925\n",
      "Epoch 9, val loss: 6.07753, train loss: 4.48928\n",
      "\n",
      "--------------------------------- Prune 80 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 5.88270, train loss: 10.14663\n",
      "Epoch 1, val loss: 5.88270 -> 5.71964, train loss: 6.61809\n",
      "Epoch 2, val loss: 5.71964 -> 4.80624, train loss: 5.36384\n",
      "Epoch 3, val loss: 4.80624 -> 4.42659, train loss: 4.72781\n",
      "Epoch 4, val loss: 7.99033, train loss: 3.84814\n",
      "Epoch 5, val loss: 4.42659 -> 4.14653, train loss: 3.43747\n",
      "Epoch 6, val loss: 6.77598, train loss: 3.14568\n",
      "Epoch 7, val loss: 5.02315, train loss: 2.72363\n",
      "Epoch 8, val loss: 4.14653 -> 4.09661, train loss: 2.58181\n",
      "Epoch 9, val loss: 4.09661 -> 3.81931, train loss: 2.15502\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 16.94960, train loss: 23.36060\n",
      "Epoch 1, val loss: 16.94960 -> 13.00165, train loss: 15.44612\n",
      "Epoch 2, val loss: 13.00165 -> 10.80214, train loss: 12.66193\n",
      "Epoch 3, val loss: 10.80214 -> 9.64241, train loss: 10.90005\n",
      "Epoch 4, val loss: 11.80801, train loss: 9.77776\n",
      "Epoch 5, val loss: 9.81208, train loss: 8.63022\n",
      "Epoch 6, val loss: 9.64241 -> 8.22720, train loss: 8.20561\n",
      "Epoch 7, val loss: 8.22720 -> 6.99974, train loss: 7.57003\n",
      "Epoch 8, val loss: 7.25366, train loss: 7.19724\n",
      "Epoch 9, val loss: 6.99974 -> 6.52760, train loss: 6.76827\n",
      "\n",
      "--------------------------------- Prune 90 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 5.95376, train loss: 10.31526\n",
      "Epoch 1, val loss: 5.95376 -> 5.35512, train loss: 6.49612\n",
      "Epoch 2, val loss: 6.54726, train loss: 5.31046\n",
      "Epoch 3, val loss: 5.35512 -> 4.77168, train loss: 4.72600\n",
      "Epoch 4, val loss: 5.43317, train loss: 4.08355\n",
      "Epoch 5, val loss: 4.77168 -> 3.84194, train loss: 3.65873\n",
      "Epoch 6, val loss: 4.55561, train loss: 3.02630\n",
      "Epoch 7, val loss: 4.44923, train loss: 2.80225\n",
      "Epoch 8, val loss: 4.07580, train loss: 2.62413\n",
      "Epoch 9, val loss: 3.84194 -> 3.78527, train loss: 2.19848\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 17.67112, train loss: 27.42979\n",
      "Epoch 1, val loss: 17.67112 -> 13.62223, train loss: 17.27546\n",
      "Epoch 2, val loss: 13.62223 -> 13.42172, train loss: 15.53999\n",
      "Epoch 3, val loss: 13.42172 -> 13.34392, train loss: 13.99481\n",
      "Epoch 4, val loss: 13.34392 -> 11.27472, train loss: 12.93303\n",
      "Epoch 5, val loss: 11.27472 -> 9.99033, train loss: 12.38406\n",
      "Epoch 6, val loss: 11.22529, train loss: 11.70599\n",
      "Epoch 7, val loss: 31.13755, train loss: 11.16363\n",
      "Epoch 8, val loss: 9.99033 -> 9.39522, train loss: 10.63276\n",
      "Epoch 9, val loss: 20.87193, train loss: 10.33175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = 'age'\n",
    "num_epochs = 10\n",
    "with open('models/model_variants/model_score_lookup_singletask.tsv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['Task', 'prune_pct', 'mean_latency', 'std_latency', 'age_r2', 'gender_f1', 'ethnicity_f1'])\n",
    "            \n",
    "for i in range(10):\n",
    "    print(f'--------------------------------- Prune {i*10} % ---------------------------------')\n",
    "    prune_pct = 1.0*i / 10\n",
    "    scores, mean_lat, std_lat = pruned_mtl_training(task, prune_pct, num_epochs, train_loader, val_loader, val_dataset)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------- Prune 0 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01855, train loss: 0.02370\n",
      "Epoch 1, val loss: 0.01855 -> 0.01581, train loss: 0.01750\n",
      "Epoch 2, val loss: 0.02191, train loss: 0.01515\n",
      "Epoch 3, val loss: 0.01592, train loss: 0.01489\n",
      "Epoch 4, val loss: 0.01682, train loss: 0.01264\n",
      "Epoch 5, val loss: 0.01581 -> 0.01332, train loss: 0.01152\n",
      "Epoch 6, val loss: 0.01385, train loss: 0.00972\n",
      "Epoch 7, val loss: 0.01349, train loss: 0.00916\n",
      "Epoch 8, val loss: 0.01485, train loss: 0.00728\n",
      "Epoch 9, val loss: 0.01685, train loss: 0.00780\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01373, train loss: 0.01066\n",
      "Epoch 1, val loss: 0.01407, train loss: 0.00906\n",
      "Epoch 2, val loss: 0.01486, train loss: 0.00984\n",
      "Epoch 3, val loss: 0.01643, train loss: 0.00744\n",
      "Epoch 4, val loss: 0.01750, train loss: 0.00504\n",
      "Epoch 5, val loss: 0.01669, train loss: 0.00456\n",
      "Epoch 6, val loss: 0.02107, train loss: 0.00466\n",
      "Epoch 7, val loss: 0.01898, train loss: 0.00356\n",
      "Epoch 8, val loss: 0.01958, train loss: 0.00636\n",
      "Epoch 9, val loss: 0.02227, train loss: 0.00346\n",
      "\n",
      "--------------------------------- Prune 10 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01714, train loss: 0.02360\n",
      "Epoch 1, val loss: 0.02860, train loss: 0.01806\n",
      "Epoch 2, val loss: 0.01772, train loss: 0.01623\n",
      "Epoch 3, val loss: 0.01714 -> 0.01467, train loss: 0.01422\n",
      "Epoch 4, val loss: 0.01467 -> 0.01366, train loss: 0.01291\n",
      "Epoch 5, val loss: 0.01366 -> 0.01320, train loss: 0.01157\n",
      "Epoch 6, val loss: 0.01764, train loss: 0.01055\n",
      "Epoch 7, val loss: 0.01427, train loss: 0.00997\n",
      "Epoch 8, val loss: 0.01703, train loss: 0.00830\n",
      "Epoch 9, val loss: 0.01715, train loss: 0.00688\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01371, train loss: 0.01092\n",
      "Epoch 1, val loss: 0.01399, train loss: 0.00918\n",
      "Epoch 2, val loss: 0.01588, train loss: 0.00869\n",
      "Epoch 3, val loss: 0.01452, train loss: 0.00685\n",
      "Epoch 4, val loss: 0.03246, train loss: 0.00626\n",
      "Epoch 5, val loss: 0.01704, train loss: 0.00672\n",
      "Epoch 6, val loss: 0.01879, train loss: 0.00445\n",
      "Epoch 7, val loss: 0.02405, train loss: 0.00410\n",
      "Epoch 8, val loss: 0.03733, train loss: 0.00339\n",
      "Epoch 9, val loss: 0.02282, train loss: 0.00309\n",
      "\n",
      "--------------------------------- Prune 20 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01851, train loss: 0.02383\n",
      "Epoch 1, val loss: 0.01851 -> 0.01630, train loss: 0.01730\n",
      "Epoch 2, val loss: 0.01630 -> 0.01427, train loss: 0.01577\n",
      "Epoch 3, val loss: 0.01494, train loss: 0.01489\n",
      "Epoch 4, val loss: 0.01453, train loss: 0.01213\n",
      "Epoch 5, val loss: 0.01650, train loss: 0.01259\n",
      "Epoch 6, val loss: 0.01618, train loss: 0.00975\n",
      "Epoch 7, val loss: 0.01427 -> 0.01423, train loss: 0.01008\n",
      "Epoch 8, val loss: 0.01423 -> 0.01376, train loss: 0.00786\n",
      "Epoch 9, val loss: 0.01887, train loss: 0.00658\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01824, train loss: 0.00721\n",
      "Epoch 1, val loss: 0.01824 -> 0.01741, train loss: 0.00642\n",
      "Epoch 2, val loss: 0.02143, train loss: 0.00541\n",
      "Epoch 3, val loss: 0.01848, train loss: 0.00565\n",
      "Epoch 4, val loss: 0.02014, train loss: 0.00341\n",
      "Epoch 5, val loss: 0.03010, train loss: 0.00359\n",
      "Epoch 6, val loss: 0.03573, train loss: 0.00356\n",
      "Epoch 7, val loss: 0.02456, train loss: 0.00295\n",
      "Epoch 8, val loss: 0.03051, train loss: 0.00281\n",
      "Epoch 9, val loss: 0.02492, train loss: 0.00237\n",
      "\n",
      "--------------------------------- Prune 30 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01952, train loss: 0.02404\n",
      "Epoch 1, val loss: 0.01952 -> 0.01602, train loss: 0.01830\n",
      "Epoch 2, val loss: 0.01602 -> 0.01400, train loss: 0.01614\n",
      "Epoch 3, val loss: 0.01462, train loss: 0.01394\n",
      "Epoch 4, val loss: 0.01400 -> 0.01325, train loss: 0.01238\n",
      "Epoch 5, val loss: 0.01752, train loss: 0.01235\n",
      "Epoch 6, val loss: 0.01512, train loss: 0.01192\n",
      "Epoch 7, val loss: 0.01467, train loss: 0.00881\n",
      "Epoch 8, val loss: 0.01722, train loss: 0.00732\n",
      "Epoch 9, val loss: 0.01661, train loss: 0.00688\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01231, train loss: 0.01264\n",
      "Epoch 1, val loss: 0.01495, train loss: 0.01063\n",
      "Epoch 2, val loss: 0.01454, train loss: 0.01002\n",
      "Epoch 3, val loss: 0.01348, train loss: 0.00832\n",
      "Epoch 4, val loss: 0.01384, train loss: 0.00692\n",
      "Epoch 5, val loss: 0.01534, train loss: 0.00609\n",
      "Epoch 6, val loss: 0.02119, train loss: 0.00602\n",
      "Epoch 7, val loss: 0.02333, train loss: 0.00444\n",
      "Epoch 8, val loss: 0.01721, train loss: 0.00443\n",
      "Epoch 9, val loss: 0.02517, train loss: 0.00389\n",
      "\n",
      "--------------------------------- Prune 40 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01960, train loss: 0.02311\n",
      "Epoch 1, val loss: 0.01960 -> 0.01703, train loss: 0.01777\n",
      "Epoch 2, val loss: 0.01703 -> 0.01269, train loss: 0.01582\n",
      "Epoch 3, val loss: 0.01356, train loss: 0.01432\n",
      "Epoch 4, val loss: 0.01431, train loss: 0.01279\n",
      "Epoch 5, val loss: 0.01269 -> 0.01265, train loss: 0.01245\n",
      "Epoch 6, val loss: 0.01865, train loss: 0.01043\n",
      "Epoch 7, val loss: 0.01462, train loss: 0.00950\n",
      "Epoch 8, val loss: 0.01297, train loss: 0.00739\n",
      "Epoch 9, val loss: 0.01390, train loss: 0.00713\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01433, train loss: 0.01335\n",
      "Epoch 1, val loss: 0.01461, train loss: 0.01103\n",
      "Epoch 2, val loss: 0.01490, train loss: 0.00939\n",
      "Epoch 3, val loss: 0.01618, train loss: 0.00794\n",
      "Epoch 4, val loss: 0.01488, train loss: 0.00715\n",
      "Epoch 5, val loss: 0.01580, train loss: 0.00578\n",
      "Epoch 6, val loss: 0.01801, train loss: 0.00543\n",
      "Epoch 7, val loss: 0.01743, train loss: 0.00430\n",
      "Epoch 8, val loss: 0.01655, train loss: 0.00401\n",
      "Epoch 9, val loss: 0.02457, train loss: 0.00342\n",
      "\n",
      "--------------------------------- Prune 50 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01639, train loss: 0.02414\n",
      "Epoch 1, val loss: 0.01654, train loss: 0.01802\n",
      "Epoch 2, val loss: 0.01639 -> 0.01489, train loss: 0.01597\n",
      "Epoch 3, val loss: 0.01489 -> 0.01359, train loss: 0.01547\n",
      "Epoch 4, val loss: 0.01473, train loss: 0.01298\n",
      "Epoch 5, val loss: 0.01409, train loss: 0.01138\n",
      "Epoch 6, val loss: 0.01704, train loss: 0.01044\n",
      "Epoch 7, val loss: 0.01394, train loss: 0.00980\n",
      "Epoch 8, val loss: 0.01622, train loss: 0.00702\n",
      "Epoch 9, val loss: 0.02343, train loss: 0.00812\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01547, train loss: 0.01844\n",
      "Epoch 1, val loss: 0.01547 -> 0.01547, train loss: 0.01436\n",
      "Epoch 2, val loss: 0.01547 -> 0.01355, train loss: 0.01244\n",
      "Epoch 3, val loss: 0.01380, train loss: 0.01115\n",
      "Epoch 4, val loss: 0.01577, train loss: 0.00972\n",
      "Epoch 5, val loss: 0.01528, train loss: 0.00909\n",
      "Epoch 6, val loss: 0.01828, train loss: 0.00740\n",
      "Epoch 7, val loss: 0.01869, train loss: 0.00644\n",
      "Epoch 8, val loss: 0.01934, train loss: 0.00571\n",
      "Epoch 9, val loss: 0.02835, train loss: 0.00476\n",
      "\n",
      "--------------------------------- Prune 60 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.02422, train loss: 0.02339\n",
      "Epoch 1, val loss: 0.02422 -> 0.01447, train loss: 0.01762\n",
      "Epoch 2, val loss: 0.01447 -> 0.01434, train loss: 0.01567\n",
      "Epoch 3, val loss: 0.01671, train loss: 0.01485\n",
      "Epoch 4, val loss: 0.01434 -> 0.01394, train loss: 0.01210\n",
      "Epoch 5, val loss: 0.01471, train loss: 0.01235\n",
      "Epoch 6, val loss: 0.01535, train loss: 0.00953\n",
      "Epoch 7, val loss: 0.01550, train loss: 0.00864\n",
      "Epoch 8, val loss: 0.01564, train loss: 0.00738\n",
      "Epoch 9, val loss: 0.01510, train loss: 0.00717\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.01680, train loss: 0.02287\n",
      "Epoch 1, val loss: 0.01680 -> 0.01511, train loss: 0.01556\n",
      "Epoch 2, val loss: 0.01511 -> 0.01453, train loss: 0.01385\n",
      "Epoch 3, val loss: 0.01536, train loss: 0.01244\n",
      "Epoch 4, val loss: 0.01453 -> 0.01450, train loss: 0.01132\n",
      "Epoch 5, val loss: 0.01802, train loss: 0.01036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, val loss: 0.02405, train loss: 0.00923\n",
      "Epoch 7, val loss: 0.01823, train loss: 0.00799\n",
      "Epoch 8, val loss: 0.01708, train loss: 0.00738\n",
      "Epoch 9, val loss: 0.01750, train loss: 0.00664\n",
      "\n",
      "--------------------------------- Prune 70 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.02250, train loss: 0.02383\n",
      "Epoch 1, val loss: 0.02250 -> 0.01722, train loss: 0.01790\n",
      "Epoch 2, val loss: 0.01722 -> 0.01380, train loss: 0.01564\n",
      "Epoch 3, val loss: 0.01380 -> 0.01372, train loss: 0.01537\n",
      "Epoch 4, val loss: 0.01387, train loss: 0.01275\n",
      "Epoch 5, val loss: 0.01372 -> 0.01360, train loss: 0.01241\n",
      "Epoch 6, val loss: 0.01377, train loss: 0.00981\n",
      "Epoch 7, val loss: 0.01449, train loss: 0.00865\n",
      "Epoch 8, val loss: 0.02866, train loss: 0.00850\n",
      "Epoch 9, val loss: 0.01414, train loss: 0.01011\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.02191, train loss: 0.02958\n",
      "Epoch 1, val loss: 0.02191 -> 0.01912, train loss: 0.02216\n",
      "Epoch 2, val loss: 0.01912 -> 0.01713, train loss: 0.01932\n",
      "Epoch 3, val loss: 0.01713 -> 0.01677, train loss: 0.01772\n",
      "Epoch 4, val loss: 0.01847, train loss: 0.01628\n",
      "Epoch 5, val loss: 0.01691, train loss: 0.01525\n",
      "Epoch 6, val loss: 0.01819, train loss: 0.01424\n",
      "Epoch 7, val loss: 0.01677 -> 0.01660, train loss: 0.01354\n",
      "Epoch 8, val loss: 0.01668, train loss: 0.01268\n",
      "Epoch 9, val loss: 0.01660 -> 0.01559, train loss: 0.01168\n",
      "\n",
      "--------------------------------- Prune 80 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01950, train loss: 0.02392\n",
      "Epoch 1, val loss: 0.01950 -> 0.01521, train loss: 0.01773\n",
      "Epoch 2, val loss: 0.01521 -> 0.01415, train loss: 0.01603\n",
      "Epoch 3, val loss: 0.01415 -> 0.01336, train loss: 0.01462\n",
      "Epoch 4, val loss: 0.01371, train loss: 0.01308\n",
      "Epoch 5, val loss: 0.01529, train loss: 0.01571\n",
      "Epoch 6, val loss: 0.01371, train loss: 0.01165\n",
      "Epoch 7, val loss: 0.01336 -> 0.01250, train loss: 0.01041\n",
      "Epoch 8, val loss: 0.01351, train loss: 0.00807\n",
      "Epoch 9, val loss: 0.01754, train loss: 0.00767\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.02549, train loss: 0.03336\n",
      "Epoch 1, val loss: 0.02549 -> 0.02186, train loss: 0.02463\n",
      "Epoch 2, val loss: 0.02186 -> 0.02000, train loss: 0.02187\n",
      "Epoch 3, val loss: 0.02000 -> 0.01859, train loss: 0.02026\n",
      "Epoch 4, val loss: 0.01914, train loss: 0.01920\n",
      "Epoch 5, val loss: 0.01927, train loss: 0.01794\n",
      "Epoch 6, val loss: 0.01859 -> 0.01796, train loss: 0.01712\n",
      "Epoch 7, val loss: 0.01796 -> 0.01765, train loss: 0.01624\n",
      "Epoch 8, val loss: 0.01826, train loss: 0.01540\n",
      "Epoch 9, val loss: 0.01771, train loss: 0.01496\n",
      "\n",
      "--------------------------------- Prune 90 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.01649, train loss: 0.02326\n",
      "Epoch 1, val loss: 0.01649 -> 0.01468, train loss: 0.01813\n",
      "Epoch 2, val loss: 0.01620, train loss: 0.01549\n",
      "Epoch 3, val loss: 0.01678, train loss: 0.01556\n",
      "Epoch 4, val loss: 0.01468 -> 0.01320, train loss: 0.01468\n",
      "Epoch 5, val loss: 0.01320 -> 0.01195, train loss: 0.01162\n",
      "Epoch 6, val loss: 0.01456, train loss: 0.01038\n",
      "Epoch 7, val loss: 0.01317, train loss: 0.00964\n",
      "Epoch 8, val loss: 0.02064, train loss: 0.00936\n",
      "Epoch 9, val loss: 0.01313, train loss: 0.00775\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.02835, train loss: 0.03349\n",
      "Epoch 1, val loss: 0.02835 -> 0.02552, train loss: 0.02716\n",
      "Epoch 2, val loss: 0.02552 -> 0.02296, train loss: 0.02490\n",
      "Epoch 3, val loss: 0.02296 -> 0.02203, train loss: 0.02412\n",
      "Epoch 4, val loss: 0.02203 -> 0.02124, train loss: 0.02312\n",
      "Epoch 5, val loss: 0.02167, train loss: 0.02256\n",
      "Epoch 6, val loss: 0.02124 -> 0.02110, train loss: 0.02221\n",
      "Epoch 7, val loss: 0.02110 -> 0.02032, train loss: 0.02156\n",
      "Epoch 8, val loss: 0.02089, train loss: 0.02120\n",
      "Epoch 9, val loss: 0.02121, train loss: 0.02083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = 'gender'\n",
    "num_epochs = 10\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'--------------------------------- Prune {i*10} % ---------------------------------')\n",
    "    prune_pct = 1.0*i / 10\n",
    "    scores, mean_lat, std_lat = pruned_mtl_training(task, prune_pct, num_epochs, train_loader, val_loader, val_dataset)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------- Prune 0 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.04358, train loss: 0.06321\n",
      "Epoch 1, val loss: 0.04358 -> 0.04009, train loss: 0.04801\n",
      "Epoch 2, val loss: 0.04009 -> 0.03717, train loss: 0.04229\n",
      "Epoch 3, val loss: 0.03729, train loss: 0.03783\n",
      "Epoch 4, val loss: 0.03717 -> 0.03474, train loss: 0.03464\n",
      "Epoch 5, val loss: 0.03596, train loss: 0.03170\n",
      "Epoch 6, val loss: 0.03474 -> 0.03464, train loss: 0.02794\n",
      "Epoch 7, val loss: 0.03677, train loss: 0.02418\n",
      "Epoch 8, val loss: 0.03700, train loss: 0.02084\n",
      "Epoch 9, val loss: 0.03949, train loss: 0.01792\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.03643, train loss: 0.02425\n",
      "Epoch 1, val loss: 0.03911, train loss: 0.02093\n",
      "Epoch 2, val loss: 0.04328, train loss: 0.01845\n",
      "Epoch 3, val loss: 0.03954, train loss: 0.01574\n",
      "Epoch 4, val loss: 0.04666, train loss: 0.01407\n",
      "Epoch 5, val loss: 0.04500, train loss: 0.01250\n",
      "Epoch 6, val loss: 0.05685, train loss: 0.01032\n",
      "Epoch 7, val loss: 0.05776, train loss: 0.01087\n",
      "Epoch 8, val loss: 0.06099, train loss: 0.00809\n",
      "Epoch 9, val loss: 0.07717, train loss: 0.00837\n",
      "\n",
      "--------------------------------- Prune 10 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.05487, train loss: 0.06289\n",
      "Epoch 1, val loss: 0.05487 -> 0.03866, train loss: 0.04756\n",
      "Epoch 2, val loss: 0.04095, train loss: 0.04168\n",
      "Epoch 3, val loss: 0.03866 -> 0.03678, train loss: 0.03719\n",
      "Epoch 4, val loss: 0.04052, train loss: 0.03390\n",
      "Epoch 5, val loss: 0.03678 -> 0.03657, train loss: 0.03077\n",
      "Epoch 6, val loss: 0.03699, train loss: 0.02727\n",
      "Epoch 7, val loss: 0.03709, train loss: 0.02300\n",
      "Epoch 8, val loss: 0.04063, train loss: 0.02004\n",
      "Epoch 9, val loss: 0.03657 -> 0.03589, train loss: 0.01823\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.04205, train loss: 0.01777\n",
      "Epoch 1, val loss: 0.04660, train loss: 0.01546\n",
      "Epoch 2, val loss: 0.04263, train loss: 0.01272\n",
      "Epoch 3, val loss: 0.05210, train loss: 0.01165\n",
      "Epoch 4, val loss: 0.04965, train loss: 0.00930\n",
      "Epoch 5, val loss: 0.07328, train loss: 0.00851\n",
      "Epoch 6, val loss: 0.04980, train loss: 0.01078\n",
      "Epoch 7, val loss: 0.05080, train loss: 0.00699\n",
      "Epoch 8, val loss: 0.05607, train loss: 0.00607\n",
      "Epoch 9, val loss: 0.07147, train loss: 0.00689\n",
      "\n",
      "--------------------------------- Prune 20 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.06075, train loss: 0.06401\n",
      "Epoch 1, val loss: 0.06075 -> 0.03987, train loss: 0.04836\n",
      "Epoch 2, val loss: 0.04107, train loss: 0.04233\n",
      "Epoch 3, val loss: 0.03987 -> 0.03629, train loss: 0.03786\n",
      "Epoch 4, val loss: 0.04440, train loss: 0.03446\n",
      "Epoch 5, val loss: 0.03703, train loss: 0.03139\n",
      "Epoch 6, val loss: 0.03629 -> 0.03346, train loss: 0.02762\n",
      "Epoch 7, val loss: 0.04203, train loss: 0.02476\n",
      "Epoch 8, val loss: 0.03670, train loss: 0.02091\n",
      "Epoch 9, val loss: 0.04259, train loss: 0.01825\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.03819, train loss: 0.02690\n",
      "Epoch 1, val loss: 0.04388, train loss: 0.02249\n",
      "Epoch 2, val loss: 0.03959, train loss: 0.01985\n",
      "Epoch 3, val loss: 0.04167, train loss: 0.01727\n",
      "Epoch 4, val loss: 0.04742, train loss: 0.01455\n",
      "Epoch 5, val loss: 0.04466, train loss: 0.01299\n",
      "Epoch 6, val loss: 0.05770, train loss: 0.01150\n",
      "Epoch 7, val loss: 0.05364, train loss: 0.00973\n",
      "Epoch 8, val loss: 0.04525, train loss: 0.01006\n",
      "Epoch 9, val loss: 0.04606, train loss: 0.00905\n",
      "\n",
      "--------------------------------- Prune 30 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.05140, train loss: 0.06350\n",
      "Epoch 1, val loss: 0.05140 -> 0.04107, train loss: 0.04764\n",
      "Epoch 2, val loss: 0.04107 -> 0.04012, train loss: 0.04196\n",
      "Epoch 3, val loss: 0.04012 -> 0.03569, train loss: 0.03829\n",
      "Epoch 4, val loss: 0.03569 -> 0.03258, train loss: 0.03546\n",
      "Epoch 5, val loss: 0.03576, train loss: 0.03070\n",
      "Epoch 6, val loss: 0.03718, train loss: 0.02749\n",
      "Epoch 7, val loss: 0.03690, train loss: 0.02396\n",
      "Epoch 8, val loss: 0.03565, train loss: 0.02136\n",
      "Epoch 9, val loss: 0.05296, train loss: 0.01727\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.03728, train loss: 0.03506\n",
      "Epoch 1, val loss: 0.03728 -> 0.03297, train loss: 0.03011\n",
      "Epoch 2, val loss: 0.03668, train loss: 0.02728\n",
      "Epoch 3, val loss: 0.04081, train loss: 0.02363\n",
      "Epoch 4, val loss: 0.04517, train loss: 0.02115\n",
      "Epoch 5, val loss: 0.05216, train loss: 0.01755\n",
      "Epoch 6, val loss: 0.04208, train loss: 0.01573\n",
      "Epoch 7, val loss: 0.05121, train loss: 0.01349\n",
      "Epoch 8, val loss: 0.04386, train loss: 0.01293\n",
      "Epoch 9, val loss: 0.05223, train loss: 0.01073\n",
      "\n",
      "--------------------------------- Prune 40 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.05013, train loss: 0.06302\n",
      "Epoch 1, val loss: 0.05013 -> 0.04419, train loss: 0.04779\n",
      "Epoch 2, val loss: 0.04419 -> 0.04381, train loss: 0.04211\n",
      "Epoch 3, val loss: 0.04381 -> 0.03413, train loss: 0.03727\n",
      "Epoch 4, val loss: 0.03484, train loss: 0.03310\n",
      "Epoch 5, val loss: 0.03606, train loss: 0.02962\n",
      "Epoch 6, val loss: 0.03422, train loss: 0.02628\n",
      "Epoch 7, val loss: 0.03675, train loss: 0.02288\n",
      "Epoch 8, val loss: 0.03623, train loss: 0.02055\n",
      "Epoch 9, val loss: 0.04397, train loss: 0.01748\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.03615, train loss: 0.04192\n",
      "Epoch 1, val loss: 0.03615 -> 0.03589, train loss: 0.03495\n",
      "Epoch 2, val loss: 0.03589 -> 0.03575, train loss: 0.03089\n",
      "Epoch 3, val loss: 0.04291, train loss: 0.02653\n",
      "Epoch 4, val loss: 0.03678, train loss: 0.02372\n",
      "Epoch 5, val loss: 0.04025, train loss: 0.02083\n",
      "Epoch 6, val loss: 0.04024, train loss: 0.01841\n",
      "Epoch 7, val loss: 0.04681, train loss: 0.01599\n",
      "Epoch 8, val loss: 0.05586, train loss: 0.01375\n",
      "Epoch 9, val loss: 0.04343, train loss: 0.01225\n",
      "\n",
      "--------------------------------- Prune 50 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.04347, train loss: 0.06219\n",
      "Epoch 1, val loss: 0.04470, train loss: 0.04734\n",
      "Epoch 2, val loss: 0.04347 -> 0.04293, train loss: 0.04135\n",
      "Epoch 3, val loss: 0.04293 -> 0.04030, train loss: 0.03790\n",
      "Epoch 4, val loss: 0.04030 -> 0.03279, train loss: 0.03393\n",
      "Epoch 5, val loss: 0.03642, train loss: 0.03058\n",
      "Epoch 6, val loss: 0.04596, train loss: 0.02682\n",
      "Epoch 7, val loss: 0.03481, train loss: 0.02444\n",
      "Epoch 8, val loss: 0.04112, train loss: 0.02080\n",
      "Epoch 9, val loss: 0.03984, train loss: 0.01803\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.04405, train loss: 0.05074\n",
      "Epoch 1, val loss: 0.04405 -> 0.04210, train loss: 0.03930\n",
      "Epoch 2, val loss: 0.04210 -> 0.04070, train loss: 0.03476\n",
      "Epoch 3, val loss: 0.04070 -> 0.03728, train loss: 0.03096\n",
      "Epoch 4, val loss: 0.03996, train loss: 0.02796\n",
      "Epoch 5, val loss: 0.03957, train loss: 0.02480\n",
      "Epoch 6, val loss: 0.04105, train loss: 0.02186\n",
      "Epoch 7, val loss: 0.04520, train loss: 0.01932\n",
      "Epoch 8, val loss: 0.04451, train loss: 0.01708\n",
      "Epoch 9, val loss: 0.04779, train loss: 0.01590\n",
      "\n",
      "--------------------------------- Prune 60 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.05387, train loss: 0.06325\n",
      "Epoch 1, val loss: 0.05387 -> 0.05041, train loss: 0.04705\n",
      "Epoch 2, val loss: 0.05041 -> 0.03608, train loss: 0.04120\n",
      "Epoch 3, val loss: 0.05539, train loss: 0.03684\n",
      "Epoch 4, val loss: 0.03791, train loss: 0.03404\n",
      "Epoch 5, val loss: 0.03769, train loss: 0.03049\n",
      "Epoch 6, val loss: 0.03608 -> 0.03442, train loss: 0.02724\n",
      "Epoch 7, val loss: 0.03442 -> 0.03436, train loss: 0.02433\n",
      "Epoch 8, val loss: 0.04089, train loss: 0.02049\n",
      "Epoch 9, val loss: 0.03984, train loss: 0.01937\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.05054, train loss: 0.07011\n",
      "Epoch 1, val loss: 0.05054 -> 0.04377, train loss: 0.04856\n",
      "Epoch 2, val loss: 0.04377 -> 0.04347, train loss: 0.04262\n",
      "Epoch 3, val loss: 0.04347 -> 0.03955, train loss: 0.03857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, val loss: 0.04448, train loss: 0.03494\n",
      "Epoch 5, val loss: 0.04178, train loss: 0.03242\n",
      "Epoch 6, val loss: 0.04094, train loss: 0.02951\n",
      "Epoch 7, val loss: 0.03955 -> 0.03833, train loss: 0.02737\n",
      "Epoch 8, val loss: 0.04147, train loss: 0.02544\n",
      "Epoch 9, val loss: 0.04621, train loss: 0.02286\n",
      "\n",
      "--------------------------------- Prune 70 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.04540, train loss: 0.06228\n",
      "Epoch 1, val loss: 0.04540 -> 0.04092, train loss: 0.04689\n",
      "Epoch 2, val loss: 0.04092 -> 0.03869, train loss: 0.04068\n",
      "Epoch 3, val loss: 0.03869 -> 0.03676, train loss: 0.03773\n",
      "Epoch 4, val loss: 0.03676 -> 0.03436, train loss: 0.03284\n",
      "Epoch 5, val loss: 0.03474, train loss: 0.03039\n",
      "Epoch 6, val loss: 0.03572, train loss: 0.02698\n",
      "Epoch 7, val loss: 0.04387, train loss: 0.02360\n",
      "Epoch 8, val loss: 0.04132, train loss: 0.02037\n",
      "Epoch 9, val loss: 0.04138, train loss: 0.01718\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.05392, train loss: 0.06754\n",
      "Epoch 1, val loss: 0.05392 -> 0.04554, train loss: 0.05316\n",
      "Epoch 2, val loss: 0.04602, train loss: 0.04698\n",
      "Epoch 3, val loss: 0.04554 -> 0.04318, train loss: 0.04341\n",
      "Epoch 4, val loss: 0.04582, train loss: 0.04092\n",
      "Epoch 5, val loss: 0.04318 -> 0.04209, train loss: 0.03788\n",
      "Epoch 6, val loss: 0.04223, train loss: 0.03590\n",
      "Epoch 7, val loss: 0.04389, train loss: 0.03397\n",
      "Epoch 8, val loss: 0.04209 -> 0.04087, train loss: 0.03188\n",
      "Epoch 9, val loss: 0.04144, train loss: 0.03016\n",
      "\n",
      "--------------------------------- Prune 80 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.05001, train loss: 0.06424\n",
      "Epoch 1, val loss: 0.05001 -> 0.04292, train loss: 0.04794\n",
      "Epoch 2, val loss: 0.04292 -> 0.04084, train loss: 0.04172\n",
      "Epoch 3, val loss: 0.04084 -> 0.03801, train loss: 0.03800\n",
      "Epoch 4, val loss: 0.03801 -> 0.03431, train loss: 0.03461\n",
      "Epoch 5, val loss: 0.03578, train loss: 0.03122\n",
      "Epoch 6, val loss: 0.03710, train loss: 0.02753\n",
      "Epoch 7, val loss: 0.03979, train loss: 0.02482\n",
      "Epoch 8, val loss: 0.03826, train loss: 0.02180\n",
      "Epoch 9, val loss: 0.05050, train loss: 0.01842\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.06357, train loss: 0.07668\n",
      "Epoch 1, val loss: 0.06357 -> 0.05743, train loss: 0.06457\n",
      "Epoch 2, val loss: 0.05743 -> 0.05200, train loss: 0.05827\n",
      "Epoch 3, val loss: 0.05235, train loss: 0.05332\n",
      "Epoch 4, val loss: 0.05200 -> 0.05009, train loss: 0.05047\n",
      "Epoch 5, val loss: 0.05009 -> 0.04817, train loss: 0.04798\n",
      "Epoch 6, val loss: 0.04817 -> 0.04470, train loss: 0.04621\n",
      "Epoch 7, val loss: 0.04526, train loss: 0.04508\n",
      "Epoch 8, val loss: 0.04673, train loss: 0.04358\n",
      "Epoch 9, val loss: 0.04732, train loss: 0.04219\n",
      "\n",
      "--------------------------------- Prune 90 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.04824, train loss: 0.06080\n",
      "Epoch 1, val loss: 0.04824 -> 0.04046, train loss: 0.04627\n",
      "Epoch 2, val loss: 0.04046 -> 0.03817, train loss: 0.04059\n",
      "Epoch 3, val loss: 0.03817 -> 0.03735, train loss: 0.03703\n",
      "Epoch 4, val loss: 0.03735 -> 0.03265, train loss: 0.03249\n",
      "Epoch 5, val loss: 0.03813, train loss: 0.02926\n",
      "Epoch 6, val loss: 0.03647, train loss: 0.02580\n",
      "Epoch 7, val loss: 0.03610, train loss: 0.02270\n",
      "Epoch 8, val loss: 0.04222, train loss: 0.01958\n",
      "Epoch 9, val loss: 0.04312, train loss: 0.01623\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.07876, train loss: 0.08464\n",
      "Epoch 1, val loss: 0.07876 -> 0.07618, train loss: 0.07904\n",
      "Epoch 2, val loss: 0.07618 -> 0.07253, train loss: 0.07643\n",
      "Epoch 3, val loss: 0.07434, train loss: 0.07444\n",
      "Epoch 4, val loss: 0.07253 -> 0.06886, train loss: 0.07313\n",
      "Epoch 5, val loss: 0.06886 -> 0.06746, train loss: 0.07171\n",
      "Epoch 6, val loss: 0.06746 -> 0.06687, train loss: 0.07069\n",
      "Epoch 7, val loss: 0.06987, train loss: 0.06967\n",
      "Epoch 8, val loss: 0.06687 -> 0.06474, train loss: 0.06842\n",
      "Epoch 9, val loss: 0.06536, train loss: 0.06755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = 'ethnicity'\n",
    "num_epochs = 10\n",
    "            \n",
    "for i in range(10):\n",
    "    print(f'--------------------------------- Prune {i*10} % ---------------------------------')\n",
    "    prune_pct = 1.0*i / 10\n",
    "    scores, mean_lat, std_lat = pruned_mtl_training(task, prune_pct, num_epochs, train_loader, val_loader, val_dataset)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sml]",
   "language": "python",
   "name": "conda-env-sml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
