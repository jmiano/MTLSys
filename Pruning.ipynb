{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1264732-55ad-44a4-8040-6de4194b2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, Subset\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "from utils import data\n",
    "from utils.data import COCODataset, getLabelMap\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e426eb-5d90-45e2-a2ec-9c1e542175b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLUNet(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_classes=60):\n",
    "        super(MTLUNet, self).__init__()\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Encoding #\n",
    "        self.enc0 = nn.Sequential(nn.Conv2d(in_channels=num_channels, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.Dropout(p=0.5))\n",
    "        self.enc1 = nn.Sequential(nn.Conv2d(in_channels=num_channels+64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.Dropout(p=0.5))\n",
    "        self.enc2 = nn.Sequential(nn.Conv2d(in_channels=num_channels+64+128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.Dropout(p=0.5))\n",
    "        self.enc3 = nn.Sequential(nn.Conv2d(in_channels=num_channels+64+128+256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(512),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(512),\n",
    "                                  nn.Dropout(p=0.5))\n",
    "        \n",
    "        # Shared Base #\n",
    "        self.shared_base = nn.Sequential(nn.Conv2d(in_channels=num_channels+64+128+256+512, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.BatchNorm2d(1024),\n",
    "                                         nn.Dropout(p=0.5))\n",
    "        \n",
    "        # Task-specific Bases\n",
    "        self.seg_base = nn.Sequential(nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.BatchNorm2d(1024),\n",
    "                                      nn.Dropout(p=0.5),\n",
    "                                      nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2, padding=0),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.BatchNorm2d(512),\n",
    "                                      nn.Dropout(p=0.5))\n",
    "        self.class_base = nn.Sequential(nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.BatchNorm2d(1024),\n",
    "                                        nn.Dropout(p=0.5))    \n",
    "        \n",
    "        # Task 1: Segmentation #\n",
    "        self.seg3 = nn.Sequential(nn.Conv2d(in_channels=num_channels+64+128+256+1024, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(512),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2, padding=0))\n",
    "        self.seg2 = nn.Sequential(nn.Conv2d(in_channels=num_channels+64+128+512, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2, padding=0))\n",
    "        self.seg1 = nn.Sequential(nn.Conv2d(in_channels=num_channels+64+256, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2, padding=0))\n",
    "        self.seg0 = nn.Sequential(nn.Conv2d(in_channels=num_channels+128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.Dropout(p=0.5),\n",
    "                                  nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        # Task 2: Classification #\n",
    "        self.class3 = nn.Sequential(nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(1024),\n",
    "                                    nn.Dropout(p=0.5),\n",
    "                                    nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(512),\n",
    "                                    nn.Dropout(p=0.5))\n",
    "        self.class2 = nn.Sequential(nn.Conv2d(in_channels=1024+512, out_channels=256, kernel_size=5, stride=1, padding=0),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.Dropout(p=0.5),\n",
    "                                    nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, stride=1, padding=0),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(256),\n",
    "                                    nn.Dropout(p=0.5))\n",
    "        self.class1 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=128, kernel_size=5, stride=1, padding=0),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.Dropout(p=0.5),\n",
    "                                    nn.Conv2d(in_channels=128, out_channels=128, kernel_size=2, stride=1, padding=0),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.Dropout(p=0.5))\n",
    "        self.class0 = nn.Conv2d(in_channels=128, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Encoding\n",
    "        \n",
    "        # Lvl 0\n",
    "        #print(f'X shape, X_0 input: {X.shape}')\n",
    "        X_0 = self.enc0(X)\n",
    "        #print(f'X_0 shape: {X_0.shape}')\n",
    "        X_0 = torch.cat((X, X_0), dim=1)  # dense connection\n",
    "        #print(f'X_0 shape: {X_0.shape}')\n",
    "        X_0_mp = self.maxpool(X_0)\n",
    "        #print(f'X_0_mp, X_1 input shape: {X_0_mp.shape}')\n",
    "        \n",
    "        # Lvl 1\n",
    "        X_1 = self.enc1(X_0_mp)\n",
    "        X_1 = torch.cat((X_0_mp, X_1), dim=1)  # dense connection\n",
    "        X_1_mp = self.maxpool(X_1)\n",
    "        #print(f'X_1_mp, X_2 input shape: {X_1_mp.shape}')\n",
    "        \n",
    "        # Lvl 2\n",
    "        X_2 = self.enc2(X_1_mp)\n",
    "        X_2 = torch.cat((X_1_mp, X_2), dim=1)  # dense connection\n",
    "        X_2_mp = self.maxpool(X_2)\n",
    "        #print(f'X_2_mp, X_3 input shape: {X_2_mp.shape}')\n",
    "        \n",
    "        # Lvl 3\n",
    "        X_3 = self.enc3(X_2_mp)\n",
    "        X_3 = torch.cat((X_2_mp, X_3), dim=1)  # dense connection\n",
    "        X_3_mp = self.maxpool(X_3)\n",
    "        #print(f'X_3_mp, shared_base input shape: {X_3_mp.shape}')\n",
    "        \n",
    "        # Base\n",
    "        shared_base = self.shared_base(X_3_mp)\n",
    "        #print(f'shared_base output shape: {shared_base.shape}')\n",
    "        \n",
    "        # Task 1: Segmentation\n",
    "        seg_output = self.seg_base(shared_base)\n",
    "        #print(f'seg_base output shape: {seg_output.shape}')\n",
    "        seg_output = torch.cat((X_3, seg_output), dim=1)  # skip connection\n",
    "        #print(f'seg3 input shape: {seg_output.shape}')\n",
    "        seg_output = self.seg3(seg_output)\n",
    "        #print(f'seg3 output shape: {seg_output.shape}')\n",
    "        \n",
    "        seg_output = torch.cat((X_2, seg_output), dim=1)  # skip connection\n",
    "        seg_output = self.seg2(seg_output)\n",
    "        #print(f'seg2 output shape: {seg_output.shape}')\n",
    "        \n",
    "        seg_output = torch.cat((X_1, seg_output), dim=1)  # skip connection\n",
    "        seg_output = self.seg1(seg_output)\n",
    "        #print(f'seg1 output shape: {seg_output.shape}')\n",
    "        \n",
    "        seg_output = torch.cat((X_0, seg_output), dim=1)  # skip connection\n",
    "        #print(f'seg0 input shape: {seg_output.shape}')\n",
    "        seg_output = self.seg0(seg_output)\n",
    "        #print(f'seg0 output shape: {seg_output.shape}')\n",
    "        \n",
    "        # Task 2: Classification\n",
    "        #print(f'class3 input shape: {shared_base.shape}')\n",
    "        class_output = self.class3(shared_base)\n",
    "        class_output = torch.cat((shared_base, class_output), dim=1)  # dense connection\n",
    "        #print(f'class3 output shape: {class_output.shape}')\n",
    "        class_output = self.class2(class_output)\n",
    "        #print(f'class2 output shape: {class_output.shape}')\n",
    "        class_output = self.class1(class_output)\n",
    "        #print(f'class1 output shape: {class_output.shape}')\n",
    "        class_output = self.class0(class_output)\n",
    "        #print(f'class0 output shape: {class_output.shape}')\n",
    "        \n",
    "        return seg_output, class_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfa0831a-478f-4a3c-b5b5-56ef256a1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, PRUNING_PERCENT=0.2, n=2, dims = 0):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            prune.ln_structured(module, name='weight', amount=PRUNING_PERCENT, n=n, dim=dims)\n",
    "            prune.remove(module, 'weight')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bf75826-5f7b-44bf-82bf-8207af6f74de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iteration 1 - Pruning 5.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 2 - Pruning 10.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 3 - Pruning 15.000000000000002% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 4 - Pruning 20.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 5 - Pruning 25.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 6 - Pruning 30.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 7 - Pruning 35.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 8 - Pruning 40.0% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 9 - Pruning 44.99999999999999% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n",
      "\n",
      "\n",
      "Iteration 10 - Pruning 49.99999999999999% of the least important neurons/filters...\n",
      "Dimension 0, norms 1\n",
      "Dimension 0, norms 2\n",
      "Dimension 1, norms 1\n",
      "Dimension 1, norms 2\n",
      "Dimension 2, norms 1\n",
      "Dimension 2, norms 2\n"
     ]
    }
   ],
   "source": [
    "PATH = 'models/test_model.pt'\n",
    "ITER_PRUNING = 10\n",
    "PRUNING_PERCENT = 0.05\n",
    "##Load trained model\n",
    "# mtlunet = torch.load(PATH)\n",
    "\n",
    "## placeholder for now --\n",
    "mtlunet = MTLUNet()\n",
    "use_gpu = False\n",
    "if use_gpu:\n",
    "    mtlunet = mtlunet.cuda()\n",
    "# mtlunet.load_state_dict(torch.load(PATH))\n",
    "mtlunet.eval()\n",
    "    \n",
    "for idx_prune in range(ITER_PRUNING):\n",
    "        print(f\"\\n\\nIteration {idx_prune+1} - Pruning {PRUNING_PERCENT*100}% of the least important neurons/filters...\")\n",
    "        dims = [0, 1, 2]\n",
    "        norms = [1, 2]\n",
    "        for dim in dims:\n",
    "            for n in norms:\n",
    "                print(f\"Dimension {dim}, norms {n}\") \n",
    "                model = copy.deepcopy(mtlunet)\n",
    "                pruned_model = prune_model(model, PRUNING_PERCENT, n=n, dims=dim)\n",
    "                      \n",
    "                ## Fine-tuning\n",
    "                      \n",
    "                ## Testing to calculate accuracy and latency\n",
    "                \n",
    "                ## Save model and update DB with accuracy and latency\n",
    "        PRUNING_PERCENT+=0.05\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d27c3f-552c-49f6-82b2-fb3160af4537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
