{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6631a-5d78-46b8-a7ed-41f3ddd4d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import sklearn.metrics as perf\n",
    "import os\n",
    "import cv2\n",
    "import torch_pruning as tp\n",
    "import copy, time\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from models.models import MTLClassifier, AgeRegressor, GenderClassifier, EthnicityClassifier\n",
    "from utils.data import FacesDataset, data_transform\n",
    "from utils.training import train_mtl_model, train_age_model, train_gender_model, train_ethnicity_model\n",
    "from utils.evaluation import run_evaluation, show_example_predictions\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35850149-6991-499a-9ad1-6ca75991623d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Load in the data\n",
    "folder = 'UTKFace'\n",
    "transform = data_transform()\n",
    "dataset = FacesDataset(folder=folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c83b1b-1805-4d33-8cd9-e0615a42c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up train and val datasets and loaders\n",
    "train_len = int(len(dataset)*0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_dataset, val_dataset = random_split(dataset, [train_len, val_len], torch.Generator().manual_seed(8))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018603f-6f07-4866-9f65-97efdd9fa652",
   "metadata": {},
   "source": [
    "PRUNING CONV Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd79dd50-869a-4e5c-a63e-782c515b924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, PRUNING_PERCENT=0.2):\n",
    "    DG = tp.DependencyGraph()\n",
    "    DG.build_dependency(model, example_inputs=torch.randn(1,3,224,224))\n",
    "    strategy = tp.strategy.L1Strategy() \n",
    "    for name, module in model.named_modules():\n",
    "        # if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            pruning_idxs = strategy(module.weight, amount=PRUNING_PERCENT) # or manually selected pruning_idxs=[2, 6, 9, ...]\n",
    "            pruning_plan = DG.get_pruning_plan(module, tp.prune_conv, idxs=pruning_idxs )\n",
    "\n",
    "            pruning_plan.exec()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4addd8-3281-44e0-a650-159d42787a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINE TUNING:\n",
    "def fine_tune(model):\n",
    "    model = model.cuda()\n",
    "    num_epochs = 5\n",
    "    age_coeff = 0.004\n",
    "    gender_coeff = 2\n",
    "    ethni_coeff = 1\n",
    "    age_criterion = nn.MSELoss()\n",
    "    gender_criterion = nn.CrossEntropyLoss()\n",
    "    ethni_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    train_mtl_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                    train_loader=train_loader, val_loader=val_loader,\n",
    "                    age_criterion=age_criterion, gender_criterion=gender_criterion, ethni_criterion=ethni_criterion,\n",
    "                    age_coeff=age_coeff, gender_coeff=gender_coeff, ethni_coeff=ethni_coeff, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f29f3d-880f-4d25-aa8b-d16b0aa58fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_time(model):\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (img, age, gender, ethnicity) in enumerate(val_loader):\n",
    "              if use_gpu:\n",
    "                img = img.cuda()\n",
    "                age = age.float().cuda()\n",
    "                gender = gender.long().cuda()\n",
    "                ethnicity = ethnicity.long().cuda()\n",
    "              \n",
    "              start = time.time()\n",
    "              # Get outputs\n",
    "              age_output, gender_output, ethnicity_output = model(img)\n",
    "              age_output = age_output.squeeze(1)\n",
    "              gender_output = gender_output\n",
    "              ethnicity_output = ethnicity_output\n",
    "\n",
    "              # Get predictions\n",
    "              age_pred = age_output\n",
    "              gender_pred = torch.argmax(gender_output, axis=1)\n",
    "              ethnicity_pred = torch.argmax(ethnicity_output, axis=1)\n",
    "              end = time.time()\n",
    "\n",
    "              inference_latency = end-start\n",
    "              print(\"Time to predict:\", inference_latency)\n",
    "\n",
    "              return inference_latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d35db7-c20e-429e-a2e4-2cbcbd27bc70",
   "metadata": {},
   "source": [
    "BASIC PRUNING CODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180a365-bc7e-45c8-87ee-d20f0e04ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/mtl_face_model_v1.pt''\n",
    "ITER_PRUNING = 15\n",
    "PRUNING_PERCENT = 0.01\n",
    "\n",
    "model = MTLClassifier()\n",
    "model.load_state_dict(torch.load('models/mtl_face_model_v1.pt'))\n",
    "if use_gpu:\n",
    "  model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4162e4-8401-4bda-9c54-838fb4d4cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['age', 'gender', 'ethnicity']\n",
    "mtl_model = True\n",
    "for idx_prune in range(ITER_PRUNING):\n",
    "        print(f\"\\n\\nIteration {idx_prune+1} - Pruning {PRUNING_PERCENT*100}% of the least important neurons in every conv\")\n",
    "        model1 = copy.deepcopy(model)\n",
    "        pruned_model = prune_model(model1, PRUNING_PERCENT)\n",
    "        if use_gpu:\n",
    "            pruned_model = pruned_model.cuda()\n",
    "        fine_tune(pruned_model)\n",
    "        if not use_gpu:\n",
    "            device = torch.device(\"cpu\")\n",
    "            pruned_model.to(device)\n",
    "        pruned_model.eval()\n",
    "        inf_time = get_inference_time(pruned_model)\n",
    "        score_dict = run_evaluation(pruned_model, val_loader, tasks, mtl_model)\n",
    "        \n",
    "        f = open(\"pruned_models/model_data.txt\", \"a\")\n",
    "        s = f'{idx_prune+1},{score_dict[\"age\"][1]},{score_dict[\"gender\"][1]},{score_dict[{\"ethnicity\"][1],{inf_time}\\n'\n",
    "        f.write(s)\n",
    "        f.close()\n",
    "        torch.save(model.state_dict(),f\"pruned_models/mtl_face_model_{idx_prune+1}.pt\")\n",
    "        PRUNING_PERCENT+=0.02\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
