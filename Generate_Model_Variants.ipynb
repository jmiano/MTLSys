{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch import nn\n",
    "from torch.nn.utils import prune\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import sklearn.metrics as perf\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch_pruning as tp\n",
    "import csv\n",
    "\n",
    "from models.models import MTLClassifier, AgeRegressor, GenderClassifier, EthnicityClassifier\n",
    "from utils.data import FacesDataset, data_transform\n",
    "from utils.training import train_mtl_model, train_age_model, train_gender_model, train_ethnicity_model\n",
    "from utils.evaluation import run_evaluation, show_example_predictions\n",
    "from utils.pruning import prune_model, prune_other_tasks, get_f1_and_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in the data\n",
    "folder = 'UTKFace'\n",
    "transform = data_transform()\n",
    "dataset = FacesDataset(folder=folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up train and val datasets and loaders\n",
    "train_len = int(len(dataset)*0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_dataset, val_dataset = random_split(dataset, [train_len, val_len], torch.Generator().manual_seed(8))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTL Model Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define pruned training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruned_mtl_training(task, prune_pct, num_epochs,\n",
    "                        train_loader=train_loader, val_loader=val_loader,\n",
    "                        val_dataset=None):\n",
    "    \n",
    "    ### Set up model, loss, and optimizer\n",
    "    if task.upper()=='MTL':\n",
    "        tasks = ['age', 'gender', 'ethnicity']\n",
    "        model = MTLClassifier()\n",
    "        model = model.cuda()\n",
    "        age_criterion = nn.MSELoss()\n",
    "        gender_criterion = nn.CrossEntropyLoss()\n",
    "        ethnicity_criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Set up and run model training\n",
    "        age_coeff = 0.004\n",
    "        gender_coeff = 2\n",
    "        ethnicity_coeff = 1\n",
    "        \n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init.pth'\n",
    "        train_mtl_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                        train_loader=train_loader, val_loader=val_loader,\n",
    "                        age_criterion=age_criterion, gender_criterion=gender_criterion, ethnicity_criterion=ethnicity_criterion,\n",
    "                        age_coeff=age_coeff, gender_coeff=gender_coeff, ethnicity_coeff=ethnicity_coeff, save=True,\n",
    "                        save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_model(model, PRUNING_PERCENT=prune_pct)\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init.pth'\n",
    "        train_mtl_model(num_epochs=num_epochs, model=pruned_model, optimizer=optimizer,\n",
    "                        train_loader=train_loader, val_loader=val_loader,\n",
    "                        age_criterion=age_criterion, gender_criterion=gender_criterion, ethnicity_criterion=ethnicity_criterion,\n",
    "                        age_coeff=age_coeff, gender_coeff=gender_coeff, ethnicity_coeff=ethnicity_coeff, save=True,\n",
    "                        save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                   eval_dataset=val_dataset,\n",
    "                                                   eval_dataloader=val_loader,\n",
    "                                                   tasks=tasks,\n",
    "                                                   mtl_model=True)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        ager2 = scores['age'][1]\n",
    "        genderf1 = scores['gender'][0]\n",
    "        ethnicityf1 = scores['ethnicity'][0]\n",
    "        row = [task.upper(), prune_pct, mean_lat, ager2, genderf1, ethnicityf1]\n",
    "        with open('models/model_variants/model_score_lookup.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "        \n",
    "    elif task.upper()=='GENDER':\n",
    "        tasks = ['gender']\n",
    "        model = GenderClassifier()\n",
    "        model = model.cuda()\n",
    "        gender_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Set up and run model training\n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init.pth'\n",
    "        train_gender_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                           train_loader=train_loader, val_loader=val_loader,\n",
    "                           gender_criterion=gender_criterion, gender_coeff=1.0,\n",
    "                           save=True, save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_other_tasks(model, task1='age', task2='ethnicity', PRUNING_PERCENT=prune_pct)\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init.pth'\n",
    "        train_gender_model(num_epochs=num_epochs, model=pruned_model, optimizer=optimizer,\n",
    "                           train_loader=train_loader, val_loader=val_loader,\n",
    "                           gender_criterion=gender_criterion, gender_coeff=1.0,\n",
    "                           save=True, save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                   eval_dataset=val_dataset,\n",
    "                                                   eval_dataloader=val_loader,\n",
    "                                                   tasks=tasks,\n",
    "                                                   mtl_model=True)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        genderf1 = scores['gender'][0]\n",
    "        row = [task.upper(), prune_pct, mean_lat, 0.0, genderf1, 0.0]\n",
    "        with open('models/model_variants/model_score_lookup.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "    elif task.upper()=='ethnicity':\n",
    "        tasks = ['ethnicity']\n",
    "        model = EthnicityClassifier()\n",
    "        model = model.cuda()\n",
    "        ethnicity_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Set up and run model training\n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init.pth'\n",
    "        train_ethnicity_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              ethnicity_criterion=ethnicity_criterion, ethnicity_coeff=1.0,\n",
    "                              save=True, save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_other_tasks(model, task1='age', task2='gender', PRUNING_PERCENT=prune_pct)\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init.pth'\n",
    "        train_ethnicity_model(num_epochs=num_epochs, model=pruned_model, optimizer=optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              ethnicity_criterion=ethnicity_criterion, ethnicity_coeff=1.0,\n",
    "                              save=True, save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                       eval_dataset=val_dataset,\n",
    "                                                       eval_dataloader=val_loader,\n",
    "                                                       tasks=tasks,\n",
    "                                                       mtl_model=True)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        ethnicityf1 = scores['ethnicity'][0]\n",
    "        row = [task.upper(), prune_pct, mean_lat, 0.0, 0.0, ethnicityf1]\n",
    "        with open('models/model_variants/model_score_lookup.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "    elif task.upper()=='AGE':\n",
    "        tasks = ['age']\n",
    "        model = AgeRegressor()\n",
    "        model = model.cuda()\n",
    "        age_criterion = nn.MSE()\n",
    "\n",
    "        # Set up and run model training\n",
    "        # Train initial model\n",
    "        print('---------------- Train Initial Model ----------------')\n",
    "        save_no_prune = f'model_variants/{task.lower()}_p-0_lat-init_f1-init.pth'\n",
    "        train_age_model(num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              age_criterion=age_criterion, age_coeff=1.0,\n",
    "                              save=True, save_name=save_no_prune)\n",
    "        \n",
    "        # Do pruning\n",
    "        model = torch.load(f'models/{save_no_prune}')\n",
    "        pruned_model = prune_other_tasks(model, task1='gender', task2='ethnicity', PRUNING_PERCENT=prune_pct)\n",
    "        \n",
    "        # Fine-tune model\n",
    "        print('-------------- Fine-tuning Pruned Model -------------')\n",
    "        save_initial = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}_lat-init_f1-init.pth'\n",
    "        train_age_model(num_epochs=num_epochs, model=pruned_model, optimizer=optimizer,\n",
    "                              train_loader=train_loader, val_loader=val_loader,\n",
    "                              age_criterion=age_criterion, age_coeff=1.0,\n",
    "                              save=True, save_name=save_initial)\n",
    "        \n",
    "        # Test latency and accuracy (F1) and save model variant (and update lookup file)\n",
    "        [scores, [mean_lat, std_lat]] = get_f1_and_lat(model_path=save_initial,\n",
    "                                                       eval_dataset=val_dataset,\n",
    "                                                       eval_dataloader=val_loader,\n",
    "                                                       tasks=tasks,\n",
    "                                                       mtl_model=True)\n",
    "        \n",
    "        # Save model with score and latency information in the model name\n",
    "        ager2 = scores['age'][1]\n",
    "        row = [task.upper(), prune_pct, mean_lat, ager2, 0.0, 0.0]\n",
    "        with open('models/model_variants/model_score_lookup.tsv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        new_name = f'model_variants/{task.lower()}_p-{int(prune_pct*100)}.pth'\n",
    "        torch.save(model, f\"models/{new_name}\")\n",
    "        \n",
    "    else:\n",
    "        print('Invalid task was specified.')\n",
    "        \n",
    "    return scores, mean_lat, std_lat\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0% to 90% Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------- Prune 0 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.11199, train loss: 0.16045\n",
      "Epoch 0, age val loss: 0.02628, gender val loss: 0.03684, ethnicity val loss: 0.04888\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.10169, train loss: 0.11915\n",
      "Epoch 0, age val loss: 0.02409, gender val loss: 0.03013, ethnicity val loss: 0.04747\n",
      "\n",
      "--------------------------------- Prune 10 % ---------------------------------\n",
      "---------------- Train Initial Model ----------------\n",
      "Epoch 0, val loss: inf -> 0.11635, train loss: 0.16354\n",
      "Epoch 0, age val loss: 0.03150, gender val loss: 0.03175, ethnicity val loss: 0.05310\n",
      "-------------- Fine-tuning Pruned Model -------------\n",
      "Epoch 0, val loss: inf -> 0.18380, train loss: 0.19348\n",
      "Epoch 0, age val loss: 0.09112, gender val loss: 0.04174, ethnicity val loss: 0.05093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = 'MTL'\n",
    "num_epochs = 1\n",
    "with open('models/model_variants/model_score_lookup.tsv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['Task', 'prune_pct', 'mean_latency', 'age_r2', 'gender_f1', 'ethnicity_f1'])\n",
    "            \n",
    "for i in range(2):\n",
    "    print(f'--------------------------------- Prune {i*10} % ---------------------------------')\n",
    "    prune_pct = 1.0*i / 10\n",
    "    scores, mean_lat, std_lat = pruned_mtl_training(task, prune_pct, num_epochs, train_loader, val_loader, val_dataset)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.532001256942749\n"
     ]
    }
   ],
   "source": [
    "test_model = MTLClassifier()\n",
    "#test_model = test_model.cuda()\n",
    "test_model.eval()\n",
    "\n",
    "start = time.time()\n",
    "for i, sample in enumerate(val_dataset):\n",
    "    image = sample[0].unsqueeze(0)#.cuda()\n",
    "    test_model(image)\n",
    "    if i >= 100:\n",
    "        break\n",
    "time_taken = time.time() - start\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26000332832336426\n"
     ]
    }
   ],
   "source": [
    "test_model = MTLClassifier()\n",
    "#test_model = test_model.cuda()\n",
    "test_model.eval()\n",
    "pruned_model = prune_model(test_model, 0.90)\n",
    "\n",
    "start = time.time()\n",
    "for i, sample in enumerate(val_dataset):\n",
    "    image = sample[0].unsqueeze(0)#.cuda()\n",
    "    pruned_model(image)\n",
    "    if i >= 100:\n",
    "        break\n",
    "time_taken = time.time() - start\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sml]",
   "language": "python",
   "name": "conda-env-sml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
